{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 树"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node(object):\n",
    "    def __init__(self):\n",
    "        self.leaf_num = 0\n",
    "        self.is_leaf = False\n",
    "        self.leaf_pred = None\n",
    "        self.split_feature = None\n",
    "        self.feature_index = None\n",
    "        self.is_continuous = None\n",
    "        self.split_feature_val = None\n",
    "        self.child = {}\n",
    "        self.high = -1\n",
    "\n",
    "\n",
    "def gini(y):\n",
    "    '''\n",
    "    计算基尼值\n",
    "    输入：y\n",
    "    返回基尼值\n",
    "    '''\n",
    "    p = y.value_counts() / y.shape[0]\n",
    "    gini =  1 - np.sum(p ** 2)\n",
    "    return gini\n",
    "\n",
    "class DecisionTree(object):\n",
    "    def __init__(self, criterion, max_high):\n",
    "        self.criterion = criterion\n",
    "        self.pruning = None\n",
    "        self.tree = None\n",
    "        self.features = None\n",
    "        self.is_continuous = None\n",
    "        self.max_high = max_high\n",
    "\n",
    "    def fit(self, X_train, y_train, is_continuous):\n",
    "        '''\n",
    "        拟合数据\n",
    "        输入：X, y\n",
    "        输出树\n",
    "        调用函数：pre_pruning(输入训练数据) \\post_pruning（输入验证数据） \\create_tree（输入训练数据）\n",
    "\n",
    "        '''\n",
    "        self.features = list(X_train.columns)\n",
    "        self.is_continuous = is_continuous\n",
    "        self.tree = self.create_tree(X_train, y_train)\n",
    "\n",
    "\n",
    "    def create_tree(self, X, y):\n",
    "        '''\n",
    "        生成树的关键函数（递归）\n",
    "        输入：X，y\n",
    "        返回树\n",
    "        调用函数：类node（生成节点，根、内点、叶节点） 、判断y的取值是否唯一 、判断X是否为空 、 y最多次数的取值 、 \n",
    "                选择最合适的特征切分choose_best_feature_to_split(输入X，y返回最合适的特征名和不纯度(连续特征的不纯度还需有最合适的切分位置))\n",
    "                若为特征的取值为离散值，对每个取值生成子树？（不会太多吗），调用create_tree(输入去掉特征的X，和y，满足特征值相等)\n",
    "                若特征的取值为连续值，按照切分位置将数据分为左子树和右子树\n",
    "        '''\n",
    "        tree = Node()\n",
    "        tree.leaf_num = 0\n",
    "        if y.nunique() == 1:\n",
    "            tree.is_leaf = True\n",
    "            tree.leaf_pred = y.values[0]\n",
    "            tree.leaf_num += 1\n",
    "            tree.high = 0\n",
    "            return tree\n",
    "        \n",
    "        if X.empty or tree.high > self.max_high or X.duplicated(keep=False).sum()==X.shape[0]:\n",
    "            tree.is_leaf = True\n",
    "            tree.leaf_pred = y.value_counts().index[0]\n",
    "            tree.leaf_num += 1\n",
    "            tree.high = 0\n",
    "            return tree\n",
    "\n",
    "        split_feature, impurity = self.choose_best_feature_to_split_gini(X, y)\n",
    "\n",
    "        tree.split_feature = split_feature\n",
    "        tree.feature_index = self.features.index(split_feature)\n",
    "        tree.impurity = impurity[0]\n",
    "\n",
    "        feature_values = X.loc[:, split_feature]\n",
    "\n",
    "        if self.is_continuous[tree.feature_index] == 1:\n",
    "            tree.is_continuous = True\n",
    "            tree.split_feature_val = impurity[1]\n",
    "            sub_X = X.copy().drop(split_feature, axis=1)\n",
    "            low_tree = '>= {:.3f}'.format(tree.split_feature_val)\n",
    "            high_tree = '< {:.3f}'.format(tree.split_feature_val)\n",
    "            low_rows = feature_values >= impurity[1]\n",
    "            high_rows = feature_values <impurity[1]\n",
    "            tree.child[high_tree] = self.create_tree(sub_X[high_rows],y[high_rows])\n",
    "            tree.child[low_tree] = self.create_tree(sub_X[low_rows], y[low_rows])\n",
    "            tree.leaf_num += tree.child[high_tree].leaf_num +tree.child[low_tree].leaf_num\n",
    "            tree.high = max(tree.child[high_tree].high, tree.child[low_tree].high)\n",
    "\n",
    "        elif self.is_continuous[tree.feature_index] == 0:\n",
    "            tree.is_continuous = False\n",
    "            high = -1\n",
    "            feature_values_unique = feature_values.unique()\n",
    "            sub_X = X.copy().drop(split_feature, axis=1)\n",
    "            for value in feature_values_unique:\n",
    "                tree.child[value] = self.create_tree(sub_X[feature_values == value], y[feature_values == value])\n",
    "                tree.leaf_num += tree.child[value].leaf_num\n",
    "                high = max(high, tree.child[value].high) \n",
    "            tree.high = high + 1\n",
    "        \n",
    "        return tree\n",
    "        \n",
    "\n",
    "    def choose_best_feature_to_split_gini(self, X, y):\n",
    "        '''\n",
    "        根据Gini选出最合适的切分特征\n",
    "        输入：X， y\n",
    "        返回最合适的切分特证名和不纯度gini指标（若为连续值还加上最好的切分值）\n",
    "        调用函数：计算gini值gini_index（输入X在某特征下的数据，y，是否为连续值，返回gini指数）\n",
    "        '''\n",
    "        best_gini = [float('inf')]\n",
    "        split_feature = None\n",
    "        features = X.columns\n",
    "        for feature in features:\n",
    "            is_continuous = self.is_continuous[self.features.index(feature)]\n",
    "            gini_index = self.get_gini_index(X[feature], y, is_continuous)\n",
    "            if gini_index[0] < best_gini[0]:\n",
    "                split_feature = feature\n",
    "                best_gini = gini_index\n",
    "        \n",
    "        return split_feature, best_gini\n",
    "\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_gini_index(feature, y, is_continuous):\n",
    "        '''\n",
    "        计算基尼指数，若为连续值，选择基尼指数最小的点作为分割点\n",
    "        输入：各特征值，y\n",
    "        返回最小的gini（和分割点）\n",
    "        调用函数：计算gini值gini（输入y，返回gini值）\n",
    "        '''\n",
    "        m = feature.shape[0]\n",
    "        feature_values_unique = sorted(feature.unique())\n",
    "        if is_continuous:\n",
    "            split_points = [(feature_values_unique[i]+feature_values_unique[i+1])/2 for i in range(len(feature_values_unique)-1)] \n",
    "            best_gini = float('inf')\n",
    "            best_split_point = None\n",
    "            for split_point in split_points:\n",
    "                part_low = y[feature <= split_point]\n",
    "                part_high = y[feature > split_point]\n",
    "                gini_index = len(part_low) / m * gini(part_low) + len(part_high) / m * gini(part_high)\n",
    "\n",
    "                if gini_index < best_gini:\n",
    "                    best_gini = gini_index\n",
    "                    best_split_point = split_point\n",
    "            return [best_gini, best_split_point]\n",
    "\n",
    "        else:\n",
    "            best_gini = 0\n",
    "            for val in feature_values_unique:\n",
    "                part = y[feature == val]\n",
    "                best_gini += len(part) / m * gini(part)\n",
    "            return [best_gini]\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        预测\n",
    "        输入：X\n",
    "        返回X对应的预测结果\n",
    "        调用函数：一条数据一条数据预测predic_for_one(输入一条数据x，返回其预测结果)\n",
    "        用循环写，递归容易栈溢出\n",
    "        '''\n",
    "        return X.apply(self.predict_by_one, axis=1)\n",
    "\n",
    "    def predict_by_one(self, x):\n",
    "        '''\n",
    "        输入x\n",
    "        输出预测结果\n",
    "        '''\n",
    "        tree = self.tree\n",
    "        while not tree.is_leaf:\n",
    "            if tree.is_continuous:\n",
    "                if x[tree.feature_index] >= tree.split_feature_val:\n",
    "                    tree = tree.child['>= {:.3f}'.format(tree.split_feature_val)]\n",
    "                else:\n",
    "                    tree = tree.child['< {:.3f}'.format(tree.split_feature_val)]\n",
    "            else:\n",
    "                tree = tree.child[x[tree.feature_index]]\n",
    "        return tree.leaf_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 森林"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class randomforest(object):\n",
    "    def __init__(self, n_trees, criterion, max_high):\n",
    "        self.trees = None\n",
    "        self.n_trees = n_trees\n",
    "        self.criterion = criterion\n",
    "        self.max_high = max_high\n",
    "    \n",
    "    def fit(self, X_train, y_train, is_continuous):\n",
    "        '''\n",
    "        拟合数据\n",
    "        输入X，y\n",
    "        输出森林\n",
    "        调用函数：决策树，拟合决策树\n",
    "        '''\n",
    "        self.trees = []\n",
    "        m = X_train.shape[0]\n",
    "        for _ in range(self.n_trees):\n",
    "            indices = np.random.choice(m,m,replace=True)\n",
    "            X_train_i = X_train.iloc[indices,:]\n",
    "            y_train_i = y_train.iloc[indices]\n",
    "            tree = DecisionTree(self.criterion,self.max_high)\n",
    "            tree.fit(X_train_i, y_train_i, is_continuous)\n",
    "            self.trees.append(tree)\n",
    "            #print(\"finished\")\n",
    "        \n",
    "    def predict(self, X):\n",
    "        '''\n",
    "        预测\n",
    "        输入X\n",
    "        输出预测值\n",
    "        '''\n",
    "        trees_predictions = [[t.predict_by_one(x) for t in self.trees] for x in X.values]\n",
    "        return self.vote(trees_predictions)\n",
    "\n",
    "    def vote(self, predictions):\n",
    "        '''\n",
    "        多数表决\n",
    "        输入predictions\n",
    "        输出最多的预测结果\n",
    "        '''\n",
    "        return [np.argmax(np.bincount(x)) for x in predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_feature(df):\n",
    "    df1 = df.iloc[:,:-1].apply(lambda column:((column - column.min()) /( column.max() - column.min()) - 0.5))\n",
    "    return df1.join(df.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "0.6912751677852349\n",
      "finished\n",
      "finished\n",
      "0.785234899328859\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "0.7785234899328859\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "0.8120805369127517\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "0.7449664429530202\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "0.7516778523489933\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "0.8120805369127517\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "0.7919463087248322\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "0.7919463087248322\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('pima_indian.csv')\n",
    "data = normalize_feature(data)\n",
    "X_train = data.iloc[:450, :-1]\n",
    "y_train = data.iloc[:450, -1]\n",
    "X_valid = data.iloc[451:600, :-1]\n",
    "y_valid = data.iloc[451:600, -1]\n",
    "X_test = data.iloc[601:, :-1]\n",
    "y_test = data.iloc[601:, -1]\n",
    "is_con = [1,1,1,1,1,1,1,1]\n",
    "acc_list = []\n",
    "for i in np.arange(1,10):    \n",
    "    forest = randomforest(i,criterion='gini',max_high=3)\n",
    "    forest.fit(X_train, y_train, is_con)\n",
    "    predictions = forest.predict(X_valid)\n",
    "    acc = np.mean(predictions == y_valid)\n",
    "    print(acc)\n",
    "    acc_list.append(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classification_report(prediction, y):\n",
    "    pred_acc = prediction == y\n",
    "    TP = (pred_acc & y == 1).sum()\n",
    "    TN = pred_acc.sum() - TP\n",
    "    FN = (y == 1).sum() - TP\n",
    "    FP = (y == 0).sum() - TN\n",
    "    P = TP / (TP + FP)\n",
    "    R = TP / (TP + FN)\n",
    "    F1_score = 2 * P * R / (P + R)\n",
    "    print('precision: %f, recall: %f, f1_score: %f'%(P, R, F1_score))\n",
    "    return P, R, F1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n",
      "finished\n",
      "trees_num: 2; acc: 0.7126\n",
      "precision: 0.687500, recall: 0.366667, f1_score: 0.478261\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "trees_num: 3; acc: 0.7545\n",
      "precision: 0.679245, recall: 0.600000, f1_score: 0.637168\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "trees_num: 4; acc: 0.7066\n",
      "precision: 0.641026, recall: 0.416667, f1_score: 0.505051\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "trees_num: 7; acc: 0.8084\n",
      "precision: 0.750000, recall: 0.700000, f1_score: 0.724138\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "finished\n",
      "trees_num: 8; acc: 0.7665\n",
      "precision: 0.723404, recall: 0.566667, f1_score: 0.635514\n"
     ]
    }
   ],
   "source": [
    "for i in [2,3,4,7,8]:    \n",
    "    forest = randomforest(i,criterion='gini',max_high=3)\n",
    "    forest.fit(X_train, y_train, is_con)\n",
    "    predictions = forest.predict(X_test)\n",
    "    acc = np.mean(predictions == y_test)\n",
    "    print(\"trees_num: %d; acc: %.4f\"%(i, acc))\n",
    "    classification_report(predictions, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
